{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUYcqbijNxz07q3y8hywUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs671/workout-progression-predictor/blob/main/ResistanceTraining_Progression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fogzOaOB0Hqu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Workout Progression Predictor - Model Training Pipeline\n",
        "Author: Daniel Romeo\n",
        "Date: 02/08/2025\n",
        "\n",
        "Training a Random Forest model to predict my next workout weights based on\n",
        "my Strong app data. Hopefully this works better than just guessing!\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Any\n",
        "import sys\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import joblib\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "# Set up logging - want to see what's happening\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# These sklearn warnings are annoying\n",
        "warnings.filterwarnings('ignore', message='X does not have valid feature names')\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "\n",
        "class WorkoutDataProcessor:\n",
        "    \"\"\"\n",
        "    Handles loading and cleaning my Strong app export data.\n",
        "    The CSV export format is pretty messy so need to clean it up.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Strong app uses these column names\n",
        "        self.column_mapping = {\n",
        "            'Exercise Name': 'exercise',\n",
        "            'Date': 'date',\n",
        "            'Weight': 'weight_kg',\n",
        "            'Reps': 'reps',\n",
        "            'RPE': 'rpe',\n",
        "            'Workout Name': 'workout_name',\n",
        "            'Duration': 'duration'\n",
        "        }\n",
        "\n",
        "    def load_and_clean_data(self, filepath: str) -> pd.DataFrame:\n",
        "        \"\"\"Load the raw CSV and clean it up\"\"\"\n",
        "        logger.info(f\"Loading workout data from {filepath}\")\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"Can't find file at {filepath}\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        logger.info(f\"Loaded {len(df):,} raw workout records\")\n",
        "\n",
        "        # Rename columns to something more pythonic\n",
        "        df = df.rename(columns=self.column_mapping)\n",
        "\n",
        "        # Fix data types - dates are usually strings in the export\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "        # Convert weight/reps to numeric, some might be strings with units\n",
        "        numeric_cols = ['weight_kg', 'reps', 'rpe']\n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # Drop obviously bad data\n",
        "        initial_count = len(df)\n",
        "        df = df.dropna(subset=['date', 'exercise', 'weight_kg', 'reps'])\n",
        "        df = df[(df['weight_kg'] > 0) & (df['reps'] > 0)].copy()\n",
        "\n",
        "        # Calculate total volume (weight x reps) - key metric for progression\n",
        "        df['volume'] = df['weight_kg'] * df['reps']\n",
        "\n",
        "        removed_count = initial_count - len(df)\n",
        "        logger.info(f\"Cleaned data: {len(df):,} records ({removed_count} bad records removed)\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_workout_sessions(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Aggregate individual sets into workout sessions.\n",
        "        For modeling, I care about the max weight per exercise per day.\n",
        "        \"\"\"\n",
        "        df['session_date'] = df['date'].dt.date\n",
        "\n",
        "        # Group by date and exercise, take max weight (heaviest set)\n",
        "        sessions = df.groupby(['session_date', 'exercise']).agg({\n",
        "            'weight_kg': 'max',        # heaviest set that day\n",
        "            'volume': 'sum',           # total volume\n",
        "            'reps': 'mean',            # average reps\n",
        "            'rpe': 'mean'              # average RPE if available\n",
        "        }).reset_index()\n",
        "\n",
        "        sessions['date'] = pd.to_datetime(sessions['session_date'])\n",
        "        sessions = sessions.sort_values(['exercise', 'date'])\n",
        "\n",
        "        logger.info(f\"Created {len(sessions):,} exercise sessions from individual sets\")\n",
        "        return sessions\n",
        "\n",
        "    def filter_exercises_for_modeling(self, sessions: pd.DataFrame,\n",
        "                                    min_sessions: int = 10, max_exercises: int = 8) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Only keep exercises with enough data points.\n",
        "        Need at least 10 sessions to build a decent model.\n",
        "        \"\"\"\n",
        "        exercise_counts = sessions['exercise'].value_counts()\n",
        "\n",
        "        # Only exercises with enough sessions\n",
        "        good_exercises = exercise_counts[exercise_counts >= min_sessions]\n",
        "\n",
        "        # Take top N exercises by frequency\n",
        "        top_exercises = good_exercises.head(max_exercises)\n",
        "\n",
        "        filtered_data = sessions[sessions['exercise'].isin(top_exercises.index)]\n",
        "\n",
        "        logger.info(f\"Selected {len(top_exercises)} exercises with sufficient data:\")\n",
        "        for exercise, count in top_exercises.items():\n",
        "            logger.info(f\"  {exercise}: {count} sessions\")\n",
        "\n",
        "        return filtered_data\n",
        "\n",
        "\n",
        "class ProgressionFeatureBuilder:\n",
        "    \"\"\"\n",
        "    Creates features for predicting progression.\n",
        "    The key insight: what I lifted last time + recovery time + how hard it felt\n",
        "    should predict what I can lift next time.\n",
        "    \"\"\"\n",
        "\n",
        "    def build_progression_sequences(self, sessions: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        For each exercise, create sequences with lag features.\n",
        "        Each row becomes: what happened last time -> what happened this time\n",
        "        \"\"\"\n",
        "        all_progression_data = []\n",
        "\n",
        "        for exercise in sessions['exercise'].unique():\n",
        "            exercise_data = sessions[sessions['exercise'] == exercise].copy()\n",
        "            exercise_data = exercise_data.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "            if len(exercise_data) < 3:  # Need at least 3 sessions to make sequences\n",
        "                continue\n",
        "\n",
        "            # Create lag features - what happened in previous session\n",
        "            exercise_data['prev_weight'] = exercise_data['weight_kg'].shift(1)\n",
        "            exercise_data['prev_rpe'] = exercise_data['rpe'].shift(1)\n",
        "            exercise_data['prev_volume'] = exercise_data['volume'].shift(1)\n",
        "\n",
        "            # Days between sessions - recovery time matters a lot\n",
        "            exercise_data['days_rest'] = exercise_data['date'].diff().dt.days\n",
        "\n",
        "            # Target: weight in next session\n",
        "            exercise_data['next_weight'] = exercise_data['weight_kg'].shift(-1)\n",
        "\n",
        "            # Session count - experience with the exercise\n",
        "            exercise_data['session_number'] = range(1, len(exercise_data) + 1)\n",
        "\n",
        "            all_progression_data.append(exercise_data)\n",
        "\n",
        "            # Log progression for this exercise\n",
        "            start_weight = exercise_data['weight_kg'].iloc[0]\n",
        "            end_weight = exercise_data['weight_kg'].iloc[-1]\n",
        "            total_progress = end_weight - start_weight\n",
        "            logger.info(f\"  {exercise}: {start_weight:.1f}kg â†’ {end_weight:.1f}kg ({total_progress:+.1f}kg total)\")\n",
        "\n",
        "        if not all_progression_data:\n",
        "            raise ValueError(\"No exercises have enough data for modeling!\")\n",
        "\n",
        "        # Combine all exercises\n",
        "        combined_data = pd.concat(all_progression_data, ignore_index=True)\n",
        "\n",
        "        # Only keep rows where we have both previous session data and next session target\n",
        "        modeling_data = combined_data[\n",
        "            combined_data['prev_weight'].notna() &\n",
        "            combined_data['next_weight'].notna()\n",
        "        ].copy()\n",
        "\n",
        "        logger.info(f\"Built {len(modeling_data)} training examples from progression sequences\")\n",
        "        return modeling_data\n",
        "\n",
        "    def prepare_model_inputs(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, LabelEncoder]:\n",
        "        \"\"\"Prepare final features and target for model training\"\"\"\n",
        "\n",
        "        # Encode exercise names as numbers\n",
        "        exercise_encoder = LabelEncoder()\n",
        "        data['exercise_encoded'] = exercise_encoder.fit_transform(data['exercise'])\n",
        "\n",
        "        # Handle missing RPE values - fill with exercise-specific median\n",
        "        # (I don't always track RPE consistently)\n",
        "        data['prev_rpe_clean'] = data.groupby('exercise')['prev_rpe'].transform(\n",
        "            lambda x: x.fillna(x.median())\n",
        "        )\n",
        "\n",
        "        # Fill any remaining missing values with overall median\n",
        "        overall_rpe = data['rpe'].median()\n",
        "        data['prev_rpe_clean'] = data['prev_rpe_clean'].fillna(overall_rpe)\n",
        "\n",
        "        # Rest days - assume 7 days if missing (weekly schedule)\n",
        "        data['days_rest'] = data['days_rest'].fillna(7.0)\n",
        "\n",
        "        # Volume - fill with median\n",
        "        data['prev_volume'] = data['prev_volume'].fillna(data['prev_volume'].median())\n",
        "\n",
        "        # These are my key features for prediction\n",
        "        feature_cols = [\n",
        "            'prev_weight',        # Most important - what did I lift last time?\n",
        "            'days_rest',          # Recovery time\n",
        "            'prev_rpe_clean',     # How hard was last session?\n",
        "            'prev_volume',        # Total work done last time\n",
        "            'session_number',     # Experience level with this exercise\n",
        "            'exercise_encoded'    # Different exercises behave differently\n",
        "        ]\n",
        "\n",
        "        X = data[feature_cols].copy()\n",
        "        y = data['next_weight'].copy()\n",
        "\n",
        "        logger.info(f\"Final feature matrix: {X.shape}\")\n",
        "        logger.info(f\"Target range: {y.min():.1f} - {y.max():.1f} kg\")\n",
        "\n",
        "        return X, y, exercise_encoder\n",
        "\n",
        "\n",
        "class WorkoutProgressionModel:\n",
        "    \"\"\"Random Forest model for predicting workout progression\"\"\"\n",
        "\n",
        "    def __init__(self, **params):\n",
        "        # These hyperparameters worked well in my experiments\n",
        "        default_config = {\n",
        "            'n_estimators': 200,      # More trees = better but slower\n",
        "            'max_depth': 15,          # Prevent overfitting\n",
        "            'min_samples_split': 5,   # Don't split on tiny groups\n",
        "            'min_samples_leaf': 2,    # Each leaf needs at least 2 samples\n",
        "            'random_state': 42,       # For reproducibility\n",
        "            'n_jobs': -1              # Use all CPU cores\n",
        "        }\n",
        "        default_config.update(params)\n",
        "\n",
        "        self.model = RandomForestRegressor(**default_config)\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train_and_evaluate(self, X: pd.DataFrame, y: pd.Series, test_size: float = 0.2):\n",
        "        \"\"\"Train the model and return performance metrics\"\"\"\n",
        "\n",
        "        # Split data - stratify by exercise to ensure each exercise is in both train/test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42,\n",
        "            stratify=X['exercise_encoded']\n",
        "        )\n",
        "\n",
        "        logger.info(f\"Training on {len(X_train)} examples\")\n",
        "        logger.info(f\"Testing on {len(X_test)} examples\")\n",
        "\n",
        "        # Train the model\n",
        "        self.model.fit(X_train, y_train)\n",
        "        self.is_trained = True\n",
        "\n",
        "        # Evaluate on test set\n",
        "        predictions = self.model.predict(X_test)\n",
        "        test_mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "        logger.info(f\"Model trained! Test MAE: {test_mae:.2f} kg\")\n",
        "\n",
        "        return {\n",
        "            'model': self.model,\n",
        "            'test_mae': test_mae,\n",
        "            'X_test': X_test,\n",
        "            'y_test': y_test,\n",
        "            'y_pred': predictions\n",
        "        }\n",
        "\n",
        "\n",
        "def analyze_exercise_performance(results: Dict, encoder: LabelEncoder) -> pd.DataFrame:\n",
        "    \"\"\"Break down model performance by individual exercise\"\"\"\n",
        "\n",
        "    test_results = results['X_test'].copy()\n",
        "    test_results['actual_weight'] = results['y_test'].values\n",
        "    test_results['predicted_weight'] = results['y_pred']\n",
        "\n",
        "    # Convert exercise codes back to names\n",
        "    test_results['exercise'] = encoder.inverse_transform(results['X_test']['exercise_encoded'])\n",
        "\n",
        "    # Calculate MAE for each exercise\n",
        "    exercise_stats = test_results.groupby('exercise').apply(\n",
        "        lambda group: pd.Series({\n",
        "            'test_samples': len(group),\n",
        "            'mae_kg': mean_absolute_error(group['actual_weight'], group['predicted_weight']),\n",
        "            'avg_actual': group['actual_weight'].mean(),\n",
        "            'avg_predicted': group['predicted_weight'].mean()\n",
        "        }), include_groups=False\n",
        "    ).round(2)\n",
        "\n",
        "    return exercise_stats\n",
        "\n",
        "\n",
        "def save_trained_model(model_obj: RandomForestRegressor, encoder: LabelEncoder,\n",
        "                      test_mae: float, feature_names: list, exercise_stats: pd.DataFrame,\n",
        "                      save_dir: str = '.'):\n",
        "    \"\"\"Save the trained model and all metadata for deployment\"\"\"\n",
        "\n",
        "    save_path = Path(save_dir)\n",
        "    save_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Save the actual model files\n",
        "    joblib.dump(model_obj, save_path / 'best_progression_model.pkl')\n",
        "    joblib.dump(encoder, save_path / 'exercise_label_encoder.pkl')\n",
        "\n",
        "    # Calculate feature importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': model_obj.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    # Create metadata file with all the info Streamlit app needs\n",
        "    model_metadata = {\n",
        "        'model_type': 'Random Forest Regressor',\n",
        "        'mae': float(test_mae),\n",
        "        'features': feature_names,\n",
        "        'feature_importance': importance_df.set_index('feature')['importance'].to_dict(),\n",
        "        'exercises': list(encoder.classes_),\n",
        "        'exercise_performance': exercise_stats.to_dict('index'),\n",
        "        'package_versions': {\n",
        "            'scikit_learn': __import__('sklearn').__version__,\n",
        "            'numpy': np.__version__,\n",
        "            'pandas': pd.__version__,\n",
        "        },\n",
        "        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
        "        'notes': 'Trained on personal Strong app data'\n",
        "    }\n",
        "\n",
        "    with open(save_path / 'model_info.json', 'w') as f:\n",
        "        json.dump(model_metadata, f, indent=2)\n",
        "\n",
        "    logger.info(f\"Model files saved to {save_path}\")\n",
        "    return importance_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run the full training pipeline\"\"\"\n",
        "\n",
        "    # Configuration - update this path to your Strong app export\n",
        "    DATA_FILE = \"/content/drive/MyDrive/ML Datasets/strong.csv\"\n",
        "    OUTPUT_DIR = \".\"\n",
        "\n",
        "    logger.info(\"Starting workout progression model training\")\n",
        "\n",
        "    try:\n",
        "        # Step 1: Load and clean the raw data\n",
        "        processor = WorkoutDataProcessor()\n",
        "        clean_data = processor.load_and_clean_data(DATA_FILE)\n",
        "\n",
        "        # Step 2: Create workout sessions\n",
        "        sessions = processor.create_workout_sessions(clean_data)\n",
        "\n",
        "        # Step 3: Filter to exercises with enough data\n",
        "        modeling_sessions = processor.filter_exercises_for_modeling(sessions)\n",
        "\n",
        "        # Step 4: Build progression features\n",
        "        feature_builder = ProgressionFeatureBuilder()\n",
        "        progression_data = feature_builder.build_progression_sequences(modeling_sessions)\n",
        "\n",
        "        # Step 5: Prepare final inputs\n",
        "        X, y, exercise_encoder = feature_builder.prepare_model_inputs(progression_data)\n",
        "\n",
        "        # Step 6: Train the model\n",
        "        model = WorkoutProgressionModel()\n",
        "        training_results = model.train_and_evaluate(X, y)\n",
        "\n",
        "        # Step 7: Analyze performance by exercise\n",
        "        exercise_performance = analyze_exercise_performance(training_results, exercise_encoder)\n",
        "\n",
        "        logger.info(\"Performance breakdown by exercise:\")\n",
        "        for exercise in exercise_performance.index:\n",
        "            stats = exercise_performance.loc[exercise]\n",
        "            logger.info(f\"  {exercise}: {stats['mae_kg']:.1f}kg MAE ({int(stats['test_samples'])} test samples)\")\n",
        "\n",
        "        # Step 8: Save everything for deployment\n",
        "        feature_importance = save_trained_model(\n",
        "            training_results['model'],\n",
        "            exercise_encoder,\n",
        "            training_results['test_mae'],\n",
        "            X.columns.tolist(),\n",
        "            exercise_performance,\n",
        "            OUTPUT_DIR\n",
        "        )\n",
        "\n",
        "        # Final summary\n",
        "        logger.info(\"=\" * 50)\n",
        "        logger.info(\"Training completed successfully!\")\n",
        "        logger.info(f\"Overall model accuracy: Â±{training_results['test_mae']:.2f} kg\")\n",
        "        logger.info(f\"Most important feature: {feature_importance.iloc[0]['feature']}\")\n",
        "        logger.info(f\"Trained on {len(X)} workout progression examples\")\n",
        "        logger.info(\"=\" * 50)\n",
        "\n",
        "        # Quick test to make sure model works\n",
        "        test_input = pd.DataFrame({\n",
        "            'prev_weight': [70.0],\n",
        "            'days_rest': [3.0],\n",
        "            'prev_rpe_clean': [7.5],\n",
        "            'prev_volume': [2000.0],\n",
        "            'session_number': [25],\n",
        "            'exercise_encoded': [0]\n",
        "        })\n",
        "\n",
        "        test_pred = training_results['model'].predict(test_input)[0]\n",
        "        logger.info(f\"Test prediction: {test_pred:.1f}kg (looks reasonable!)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Training failed: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}